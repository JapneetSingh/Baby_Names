{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Iskandar/anaconda/lib/python2.7/site-packages/pandas/computation/__init__.py:19: UserWarning: The installed version of numexpr 2.4.4 is not supported in pandas and will be not be used\n",
      "\n",
      "  UserWarning)\n",
      "/Users/Iskandar/anaconda/lib/python2.7/site-packages/matplotlib/__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import mode\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download , Extract and  Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Iskandar/Desktop/DataSciecneJobHunt/CapitalONe/c1 data science challenge\r\n"
     ]
    }
   ],
   "source": [
    "# Constants to be used ahead\n",
    "\n",
    "data_path = \"user_data\" \n",
    "ssa_url = 'http://www.ssa.gov/oact/babynames/state/namesbystate.zip'\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download_extract_load(data_path,web_url):\n",
    "    '''\n",
    "    Downloads and extracts data and then calls read_in_babynames() function to load the data to a dataframe\n",
    "    INPUT:\n",
    "    data_path - path where data needs to be downlaoded. By default works in the current working directory\n",
    "    web_url - url path to the babynames zipfile\n",
    "    \n",
    "    OUTPUT:\n",
    "    \n",
    "    data -  data frame with data loaded\n",
    "    '''\n",
    "    # creates path if it does not exist\n",
    "    if not os.path.isdir(data_path): \n",
    "        os.makedirs(data_path)\n",
    "    \n",
    "    #Change directory to data path\n",
    "    os.chdir(data_path)\n",
    "    \n",
    "    #Download Data if not already downloaded\n",
    "    if not os.path.isfile(\"names.zip\"):\n",
    "        print \"Downloading.\"\n",
    "        import urllib\n",
    "        urllib.urlretrieve(ssa_url, 'names.zip')\n",
    "    \n",
    "    else: print \"Data already downloaded.\"\n",
    "    print\"Downloading complete.\"    \n",
    "    \n",
    "    if not os.path.isfile(\"AL.txt\") or not os.path.isfile(\"WY.txt\"):\n",
    "        print \"Extracting.\"\n",
    "        import zipfile\n",
    "        with zipfile.ZipFile('names.zip') as zf:\n",
    "            #for member in zf.infolist():#Alternate method\n",
    "                #zf.extract(member)\n",
    "            zf.extractall() \n",
    "        \n",
    "    else: print \"Data already extracted.\"\n",
    "    print\"Extraction complete!!\"\n",
    "    \n",
    "    data = read_in_babynames()\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_in_babynames():\n",
    "    \"\"\"\n",
    "    Reads in data from a given location\n",
    "    INPUT:\n",
    "    None\n",
    "    \n",
    "    OUTPUT:\n",
    "    data- dataframe containing the contents of all the files\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    # List of all state(+DC = 51 in total) names to be used for reading in the files\n",
    "    states = ['AL','AK','AZ','AR','CA','CO','CT','DC','DE','FL','GA','HI','ID','IL','IN','IA','KS','KY','LA',\n",
    "    'ME','MD','MA','MI','MN','MS','MO','MT','NE','NV','NH','NJ','NM','NY','NC','ND','OH','OK','OR','PA',\n",
    "    'RI','SC','SD','TN','TX','UT','VT','VA','WA','WV','WI','WY']\n",
    "    \n",
    "    \n",
    "    # Change working directory to the location of the files\n",
    "    #os.chdir(path_to_files)\n",
    "    \n",
    "    # Initializing an empty dataframe to read in the data\n",
    "    data = pd.DataFrame()\n",
    "    counter = 0\n",
    "    \n",
    "    for state in states:\n",
    "        counter+=1\n",
    "        filename =  state +'.txt'\n",
    "        #print filename as a check\n",
    "        print \"%d)%s loaded\"%(counter,state)\n",
    "        # The files dont have headers\n",
    "        temp_data =  pd.read_csv(filename,sep = \",\",header=None)\n",
    "        data = data.append(temp_data)\n",
    "    \n",
    "    # Set column names\n",
    "    data.columns = [\"state\",\"gender\",\"year\",\"name\",\"state_frequency\"]\n",
    "    print \"Data load is now complete. Do your thing!!\"\n",
    "    return data\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading.\n",
      "Downloading complete.\n",
      "Extracting.\n",
      "Extraction complete!!\n",
      "1)AL loaded\n",
      "2)AK loaded\n",
      "3)AZ loaded\n",
      "4)AR loaded\n",
      "5)CA loaded\n",
      "6)CO loaded\n",
      "7)CT loaded\n",
      "8)DC loaded\n",
      "9)DE loaded\n",
      "10)FL loaded\n",
      "11)GA loaded\n",
      "12)HI loaded\n",
      "13)ID loaded\n",
      "14)IL loaded\n",
      "15)IN loaded\n",
      "16)IA loaded\n",
      "17)KS loaded\n",
      "18)KY loaded\n",
      "19)LA loaded\n",
      "20)ME loaded\n",
      "21)MD loaded\n",
      "22)MA loaded\n",
      "23)MI loaded\n",
      "24)MN loaded\n",
      "25)MS loaded\n",
      "26)MO loaded\n",
      "27)MT loaded\n",
      "28)NE loaded\n",
      "29)NV loaded\n",
      "30)NH loaded\n",
      "31)NJ loaded\n",
      "32)NM loaded\n",
      "33)NY loaded\n",
      "34)NC loaded\n",
      "35)ND loaded\n",
      "36)OH loaded\n",
      "37)OK loaded\n",
      "38)OR loaded\n",
      "39)PA loaded\n",
      "40)RI loaded\n",
      "41)SC loaded\n",
      "42)SD loaded\n",
      "43)TN loaded\n",
      "44)TX loaded\n",
      "45)UT loaded\n",
      "46)VT loaded\n",
      "47)VA loaded\n",
      "48)WA loaded\n",
      "49)WV loaded\n",
      "50)WI loaded\n",
      "51)WY loaded\n",
      "Data load is now complete. Do your thing!!\n"
     ]
    }
   ],
   "source": [
    "data = download_extract_load(data_path,ssa_url)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive analysis - THE QUERIES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state              0\n",
       "gender             0\n",
       "year               0\n",
       "name               0\n",
       "state_frequency    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look for missing data\n",
    "data.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>gender</th>\n",
       "      <th>year</th>\n",
       "      <th>name</th>\n",
       "      <th>state_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>F</td>\n",
       "      <td>1910</td>\n",
       "      <td>Mary</td>\n",
       "      <td>875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL</td>\n",
       "      <td>F</td>\n",
       "      <td>1910</td>\n",
       "      <td>Annie</td>\n",
       "      <td>482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL</td>\n",
       "      <td>F</td>\n",
       "      <td>1910</td>\n",
       "      <td>Willie</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AL</td>\n",
       "      <td>F</td>\n",
       "      <td>1910</td>\n",
       "      <td>Mattie</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AL</td>\n",
       "      <td>F</td>\n",
       "      <td>1910</td>\n",
       "      <td>Ruby</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state gender  year    name  state_frequency\n",
       "0    AL      F  1910    Mary              875\n",
       "1    AL      F  1910   Annie              482\n",
       "2    AL      F  1910  Willie              257\n",
       "3    AL      F  1910  Mattie              232\n",
       "4    AL      F  1910    Ruby              204"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Name the columns\n",
    "data.columns = [\"state\",\"gender\",\"year\",\"name\",\"state_frequency\"]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state              object\n",
       "gender             object\n",
       "year                int64\n",
       "name               object\n",
       "state_frequency     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state              object\n",
       "gender             object\n",
       "year                int64\n",
       "name               object\n",
       "state_frequency     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CHanging the columns to string\n",
    "data['state'] = map(lambda x: str(x),data['state'])\n",
    "data['name'] = map(lambda x: str(x),data['name'])\n",
    "data['gender'] = map(lambda x: str(x),data['gender'])\n",
    "\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All things seem in order. Proceeding with Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.  Please describe the format of the data files. Can you identify any limitations or distortions of the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is stored in tall format in ***comma seperated text files***, one for each state.\n",
    "Each row has five values:\n",
    "* **state**: the 2-letter code of the state.\n",
    "* **gender**: one letter, M|F.\n",
    "* **year**: the year of birth for this record, in 4-digit format.\n",
    "* **name**: the name.\n",
    "* **state_frequency**: an integer for the number of times this name occurred in that state in that year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the description provided by SSA, it is mentioned that only names which occur 5 or more times in an year are included\n",
    "which introduces bias into the data. Hence this data is not a comprehensive representation of all baby names in America.\n",
    "This bias also limits our ability to get an idea of population since we have no idea how many babies with names that \n",
    "occur less than 5 times exist in each state. I would therefore be careful about any generalizations from this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  What is the most popular name of all time? (Of either gender.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>state_frequency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">M</th>\n",
       "      <th>James</th>\n",
       "      <td>10504600</td>\n",
       "      <td>4938965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>John</th>\n",
       "      <td>10506510</td>\n",
       "      <td>4829733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Robert</th>\n",
       "      <td>10496851</td>\n",
       "      <td>4710600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Michael</th>\n",
       "      <td>9932640</td>\n",
       "      <td>4295779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>William</th>\n",
       "      <td>10506510</td>\n",
       "      <td>3829026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <th>Mary</th>\n",
       "      <td>10430202</td>\n",
       "      <td>3730856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">M</th>\n",
       "      <th>David</th>\n",
       "      <td>10447162</td>\n",
       "      <td>3554102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Richard</th>\n",
       "      <td>10427952</td>\n",
       "      <td>2529952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Joseph</th>\n",
       "      <td>10489225</td>\n",
       "      <td>2479602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Charles</th>\n",
       "      <td>10491166</td>\n",
       "      <td>2244617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    year  state_frequency\n",
       "gender name                              \n",
       "M      James    10504600          4938965\n",
       "       John     10506510          4829733\n",
       "       Robert   10496851          4710600\n",
       "       Michael   9932640          4295779\n",
       "       William  10506510          3829026\n",
       "F      Mary     10430202          3730856\n",
       "M      David    10447162          3554102\n",
       "       Richard  10427952          2529952\n",
       "       Joseph   10489225          2479602\n",
       "       Charles  10491166          2244617"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 10 names\n",
    "(data.groupby(['gender','name']).sum().sort_values(by = [\"state_frequency\"],ascending = False))[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The most popular name by itself is ***James***\n",
    "We can see here that the most popular name for :\n",
    "\n",
    "Women is **Mary** \n",
    "\n",
    "Men is **James**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.  What is the most gender ambiguous name in 2013? 1945?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_common_names(year, data):\n",
    "    \n",
    "    '''\n",
    "    Returns common names for males and females for a given year\n",
    "    \n",
    "    INPUT:\n",
    "    year - year for which this needs doing\n",
    "    data - data\n",
    "    \n",
    "    OUTPUT:\n",
    "    names -  set with unisex names\n",
    "    '''\n",
    "    df = data[data['year'] == year]\n",
    "    m_names = set(df[df['gender']=='M']['name'])\n",
    "    f_names = set(df[df['gender']=='F']['name'])\n",
    "    \n",
    "    common_names =  m_names.intersection(f_names)\n",
    "    return common_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Finding the names that appear in both male and female \n",
    "common_names_2013 =  find_common_names(2013,data)\n",
    "common_names_1945 =  find_common_names(1945,data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Gender ambiguity:\n",
    "At this point we need to devise a metric to measure gender-ambiguity \n",
    "We look at it as the *name that has the similar percent as males as females asssociated with it:\n",
    "* per_f = percentage of times the name appears as female\n",
    "* per_m = percentage of times the name appears as male\n",
    "\n",
    "**diff = per_f-per_m ~ 0**\n",
    "\n",
    "Since per_f = 1- per_m  so **difference** can be reworked as ***abs(2*perf_m-1)***.\n",
    "\n",
    "We do the reworking because it prevents us from having to use and extra self join in the future\n",
    "when we need to calculate the difference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gender_ambi(data, year):\n",
    "    '''\n",
    "    function to give the most data ambiguous names\n",
    "    \n",
    "    INPUT:\n",
    "    data -  your data\n",
    "    year -  year for which this operation names to be performed\n",
    "    OUTPUT:\n",
    "     \n",
    "    list_of_ga_names - list of most gender ambiguous names\n",
    "    \n",
    "     \n",
    "    '''\n",
    "    \n",
    "    # Get the set of gender ambiguous names\n",
    "    ga_names = find_common_names(year,data)\n",
    "    \n",
    "    # Subset data to get a dataframe with gender ambiguous names for that year.\n",
    "    df = data[data['year'] == year]\n",
    "    df_ga = df[(df['name'].isin(ga_names))]\n",
    "    \n",
    "    # Calculating the groupby and sum. Reset index ensures we can use the groupby indexes as columns \n",
    "    #and access them easily for future funtions. It does the following 3 things\n",
    "    #1) groups by given columns and removes years as a possible column by choosing stat_frequency \n",
    "    #2) then sums the groupby values\n",
    "    #3) Resets index \n",
    "    df = df_ga.groupby(['name','gender'])['state_frequency'].sum().reset_index()\n",
    "    \n",
    "    # We calculate a second dataframe to count the total number of occurances for each name. Will be used to calculate\n",
    "    # the percent male/female for each name\n",
    "    tot_names = df_ga.groupby(['name']).sum().reset_index()\n",
    "    \n",
    "    \n",
    "    # Merging the two using left join so I have the values aligned to calcuate the percent\n",
    "    df_vals = pd.merge(df,tot_names,on='name',how='left')\n",
    "    \n",
    "    # Removing all the rows with gender = \"F\" as not needed going forward based on gender ambiguity formula\n",
    "    df_final = df_vals[df_vals['gender'] == \"M\"]\n",
    "    \n",
    "    # Calculating the percent of male names and then the final difference using the formulae described above\n",
    "    df_final['per_m'] = df_final['state_frequency_x']/df_final['state_frequency_y']\n",
    "    df_final['diff'] = abs(2*df_final['per_m']-1)\n",
    "    \n",
    "    # Sort the final data frame by \n",
    "    ga = df_final.sort_values(by = [\"diff\"]).reset_index(True)\n",
    "    min_diff = ga['diff'].min()\n",
    "    \n",
    "    # deriving the final list of names by finding the minimum difference\n",
    "    solns = ga[ga['diff'] == min_diff]\n",
    "    list_of_ga_names = solns['name']\n",
    "    \n",
    "    return list_of_ga_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Iskandar/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/Iskandar/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    Nikita\n",
       "1    Devine\n",
       "2     Arlin\n",
       "3     Sonam\n",
       "4      Cree\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_ambi(data,2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Iskandar/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/Iskandar/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    Maxie\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_ambi(data,1945)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Maxie** is the most gender ambiguous name for 1945 while \n",
    "for 2013 we have \n",
    "**Nikita, Devine, Cree, Sonam and Arlin**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 4.  Of the names represented in the data, find the name that has had the largest percentage increase in popularity since 1980. Largest decrease?\n",
    "\n",
    "### 5.  Can you identify names that may have had an even larger increase or decrease in popularity?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function solves for both of the above. We can use the Boolean consider_all to get the answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>gender</th>\n",
       "      <th>year</th>\n",
       "      <th>name</th>\n",
       "      <th>state_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>F</td>\n",
       "      <td>1910</td>\n",
       "      <td>Mary</td>\n",
       "      <td>875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL</td>\n",
       "      <td>F</td>\n",
       "      <td>1910</td>\n",
       "      <td>Annie</td>\n",
       "      <td>482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL</td>\n",
       "      <td>F</td>\n",
       "      <td>1910</td>\n",
       "      <td>Willie</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AL</td>\n",
       "      <td>F</td>\n",
       "      <td>1910</td>\n",
       "      <td>Mattie</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AL</td>\n",
       "      <td>F</td>\n",
       "      <td>1910</td>\n",
       "      <td>Ruby</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state gender  year    name  state_frequency\n",
       "0    AL      F  1910    Mary              875\n",
       "1    AL      F  1910   Annie              482\n",
       "2    AL      F  1910  Willie              257\n",
       "3    AL      F  1910  Mattie              232\n",
       "4    AL      F  1910    Ruby              204"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def inc_dec(year1,year2,data, inc = True, consider_all=True):\n",
    "    '''\n",
    "    In this case we consider also the names that did not exist in 1980,2014\n",
    "    \n",
    "    INPUT:\n",
    "    \n",
    "    year1,year2 - Years we wish to compare. \n",
    "    data -  your data\n",
    "    inc - Boolen to decide whether to calculate increase or decrease. By default we calculate the increase\n",
    "    consider_all- boolean consider all the names including the ones that didnt exist in 1980\n",
    "    \n",
    "    OUTPUT:\n",
    "    \n",
    "    soln - dataframe containing with max inc/dec and the value of inc/dec\n",
    "    \n",
    "    '''\n",
    "    # Subset the database for specified years\n",
    "    df1 = data[data['year'] == year1].reset_index(True)\n",
    "    df2 = data[data['year'] == year2].reset_index(True)\n",
    "    \n",
    "    # Calculating the total appearances of each name for both the years\n",
    "    names_y1 = df1.groupby(['name']).sum()['state_frequency'].reset_index(True)\n",
    "    names_y2 = df2.groupby(['name']).sum()['state_frequency'].reset_index(True)\n",
    "\n",
    "    # COmbining the two to form a master dataframe with 3 columns:\n",
    "    #1) name\n",
    "    #2) y1_freq \n",
    "    #3) y2_freq\n",
    "\n",
    "    df = pd.merge(names_y1,names_y2,how = 'outer',on= 'name')\n",
    "    df.columns = ['name','y1_freq','y2_freq']\n",
    "    \n",
    "\n",
    "    \n",
    "    # Fill any null values with 0\n",
    "    df.fillna(0,inplace = True)\n",
    "    \n",
    "    # Adding Laplacian smooting. Because if the increase is from 0 we get inf percent. So increasing all occurances by 1\n",
    "    df['y1_freq'] +=1\n",
    "    df['y2_freq'] +=1\n",
    "    \n",
    "    #Subsetting the data based on whether we're calculating increase\n",
    "    if inc:\n",
    "        # Get a subset where y2_freq (2014)>y1_freq(1980)\n",
    "        \n",
    "        dfinc = df[df['y2_freq']>df['y1_freq']]\n",
    "        dfinc['diff'] = (dfinc['y2_freq'] - dfinc['y1_freq'])\n",
    "        dfinc['perc'] = dfinc['diff'] /  dfinc['y1_freq']\n",
    "        print \n",
    "        # Sort the final data frame by \n",
    "        dfinc = dfinc.sort_values(by = [\"perc\"] , ascending = False).reset_index(True)\n",
    "        \n",
    "        if not consider_all:\n",
    "        # If we only wish to consider the names that existed in 1980. Since their value has been set to 1\n",
    "            dfinc =  dfinc[dfinc['y1_freq'] > 1]\n",
    "        \n",
    "        max_inc = dfinc['perc'].max()\n",
    "        \n",
    "        soln =dfinc[dfinc[\"perc\"] == max_inc][[\"name\",\"perc\"]]        \n",
    "      \n",
    "    #Subsetting the data based on whether we're calculating decrease\n",
    "    else:     \n",
    "        # Get a subset where y1_freq (1980)>y2_freq(2014)\n",
    "        dfdec = df[df['y1_freq']>df['y2_freq']]\n",
    "        dfdec['diff'] = (dfdec['y1_freq'] - dfdec['y2_freq'])\n",
    "        dfdec['perc'] = dfdec['diff'] /  dfdec['y1_freq']\n",
    "        \n",
    "        # Sort the final data frame by \n",
    "        dfdec = dfdec.sort_values(by = [\"perc\"] , ascending = False).reset_index(True)\n",
    "        max_dec = dfdec['perc'].max()\n",
    "        soln =dfdec[dfdec[\"perc\"] == max_dec][[\"name\",\"perc\"]]\n",
    "        \n",
    "    \n",
    "    return soln"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Largest decrease not considering all(only the names that existed in 1980)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Iskandar/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/Iskandar/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tonya</td>\n",
       "      <td>0.999675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name      perc\n",
       "0  Tonya  0.999675"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inc_dec(1980,2014,data, inc= False, consider_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Largest increase not considering all (only the names that existed in 1980)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Iskandar/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/Iskandar/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Colton</td>\n",
       "      <td>1055.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name    perc\n",
       "114  Colton  1055.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inc_dec(1980,2014,data, inc = True, consider_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Largest decrease considering all (including the names that did not exist in 1980)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Iskandar/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/Iskandar/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tonya</td>\n",
       "      <td>0.999675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name      perc\n",
       "0  Tonya  0.999675"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inc_dec(1980,2014,data, inc= False, consider_all=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Largest increase considering all (including the names that did not exist in 1980)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Iskandar/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/Iskandar/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jayden</td>\n",
       "      <td>13419.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name     perc\n",
       "0  Jayden  13419.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inc_dec(1980,2014,data, inc = True, consider_all=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Biggest increase considering only the names that existed in 1980 ***Colton*** \n",
    "\n",
    "Biggest decrease for both with all and without all  ***Tonya***\n",
    "\n",
    "Biggest increase considering all the names ***Jayden***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar',\n",
    "                           'foo', 'bar', 'foo', 'foo'],\n",
    "                   'B' : ['one', 'one', 'two', 'three',\n",
    "                           'two', 'two', 'one', 'three'],\n",
    "                      'C' : np.random.randn(8),\n",
    "                     'D' : np.random.randn(8)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>foo</td>\n",
       "      <td>one</td>\n",
       "      <td>-0.251833</td>\n",
       "      <td>-1.102170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bar</td>\n",
       "      <td>one</td>\n",
       "      <td>0.116685</td>\n",
       "      <td>0.775409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>foo</td>\n",
       "      <td>two</td>\n",
       "      <td>-1.386834</td>\n",
       "      <td>1.246479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bar</td>\n",
       "      <td>three</td>\n",
       "      <td>2.215657</td>\n",
       "      <td>-0.810762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>foo</td>\n",
       "      <td>two</td>\n",
       "      <td>0.046645</td>\n",
       "      <td>-0.406791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bar</td>\n",
       "      <td>two</td>\n",
       "      <td>0.989874</td>\n",
       "      <td>-2.178078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>foo</td>\n",
       "      <td>one</td>\n",
       "      <td>-1.334310</td>\n",
       "      <td>0.888156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>foo</td>\n",
       "      <td>three</td>\n",
       "      <td>0.538030</td>\n",
       "      <td>0.542912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A      B         C         D\n",
       "0  foo    one -0.251833 -1.102170\n",
       "1  bar    one  0.116685  0.775409\n",
       "2  foo    two -1.386834  1.246479\n",
       "3  bar  three  2.215657 -0.810762\n",
       "4  foo    two  0.046645 -0.406791\n",
       "5  bar    two  0.989874 -2.178078\n",
       "6  foo    one -1.334310  0.888156\n",
       "7  foo  three  0.538030  0.542912"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">bar</th>\n",
       "      <th>one</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>three</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">foo</th>\n",
       "      <th>one</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>three</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           C  D\n",
       "A   B          \n",
       "bar one    1  1\n",
       "    three  1  1\n",
       "    two    1  1\n",
       "foo one    2  2\n",
       "    three  1  1\n",
       "    two    2  2"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = df.groupby(['A','B'])\n",
    "grouped.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def inc_dec_max(year1,year2,data, inc = True, consider_all =True):\n",
    "    '''\n",
    "    In this case we consider also the names that did not exist in 1980,2014\n",
    "    \n",
    "    INPUT:\n",
    "    \n",
    "    year1,year2 - Years we wish to compare. \n",
    "    data -  your data\n",
    "    inc - Boolen to decide whether to calculate increase or decrease. By default we calculate the increase\n",
    "    \n",
    "    OUTPUT:\n",
    "    \n",
    "    soln - dataframe containing with max inc/dec and the value of inc/dec\n",
    "    \n",
    "    '''\n",
    "    # Subset the database for specified years\n",
    "    df1 = data[data['year'] == year1].reset_index(True)\n",
    "    df2 = data[data['year'] == year2].reset_index(True)\n",
    "    \n",
    "    # Calculating the total appearances of each name for both the years\n",
    "    names_y1 = df1.groupby(['name']).sum()['state_frequency'].reset_index(True)\n",
    "    names_y2 = df2.groupby(['name']).sum()['state_frequency'].reset_index(True)\n",
    "\n",
    "    # COmbining the two to form a master dataframe with 3 columns:\n",
    "    #1) name\n",
    "    #2) y1_freq \n",
    "    #3) y2_freq\n",
    "\n",
    "    df = pd.merge(names_y1,names_y2,how = 'outer',on= 'name')\n",
    "    df.columns = ['name','y1_freq','y2_freq']\n",
    "    \n",
    "    if not consider_all:\n",
    "        df = df[ ~(df['y1_freq'].isnull())]\n",
    "       \n",
    "      \n",
    "    # Fill any null values with 0\n",
    "    df.fillna(0,inplace = True)\n",
    "\n",
    "    # Adding Laplacian smooting. Because if the increase is from 0 we get inf percent. So increasing all occurances by 1\n",
    "    df['y1_freq'] +=1\n",
    "    df['y2_freq'] +=1\n",
    "\n",
    "    \n",
    "    #Subsetting the data based on whether we're calculating increase or decrease\n",
    "    if inc:\n",
    "        \n",
    "        # Get a subset where y2_freq (2014)>y1_freq(1980)\n",
    "        dfinc = df[df['y2_freq']>df['y1_freq']]\n",
    "        dfinc['diff'] = (dfinc['y2_freq'] - dfinc['y1_freq'])\n",
    "        dfinc['perc'] = dfinc['diff'] /  dfinc['y1_freq']\n",
    "        \n",
    "        # Sort the final data frame by \n",
    "        dfinc = dfinc.sort_values(by = [\"perc\"] , ascending = False).reset_index(True)\n",
    "        max_inc = dfinc['perc'].max()\n",
    "        soln =dfinc[dfinc[\"perc\"] == max_inc][[\"name\",\"perc\"]]\n",
    "        \n",
    "        \n",
    "    else:     \n",
    "        \n",
    "        # Get a subset where y1_freq (1980)>y2_freq(2014)\n",
    "        dfdec = df[df['y1_freq']>df['y2_freq']]\n",
    "        dfdec['diff'] = (dfdec['y1_freq'] - dfdec['y2_freq'])\n",
    "        dfdec['perc'] = dfdec['diff'] /  dfdec['y1_freq']\n",
    "        \n",
    "        # Sort the final data frame by \n",
    "        dfdec = dfdec.sort_values(by = [\"perc\"] , ascending = False).reset_index(True)\n",
    "        max_dec = dfdec['perc'].max()\n",
    "        soln =dfdec[dfdec[\"perc\"] == max_dec][[\"name\",\"perc\"]]\n",
    "    return soln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Iskandar/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/Iskandar/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jill</td>\n",
       "      <td>0.99978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name     perc\n",
       "0  Jill  0.99978"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inc_dec_max(1980,201,data,False,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Iskandar/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/Iskandar/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "a,b=inc_dec_max(1980,2013,data,True,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Colton</td>\n",
       "      <td>1075.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name         perc\n",
       "0  Colton  1075.833333"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>name</th>\n",
       "      <th>y1_freq</th>\n",
       "      <th>y2_freq</th>\n",
       "      <th>diff</th>\n",
       "      <th>perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1061</td>\n",
       "      <td>Colton</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6461.0</td>\n",
       "      <td>6455.0</td>\n",
       "      <td>1075.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>382</td>\n",
       "      <td>Aria</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5117.0</td>\n",
       "      <td>5111.0</td>\n",
       "      <td>851.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2195</td>\n",
       "      <td>Isabella</td>\n",
       "      <td>24.0</td>\n",
       "      <td>17574.0</td>\n",
       "      <td>17550.0</td>\n",
       "      <td>731.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5040</td>\n",
       "      <td>Skylar</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4225.0</td>\n",
       "      <td>4219.0</td>\n",
       "      <td>703.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1077</td>\n",
       "      <td>Cooper</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4911.0</td>\n",
       "      <td>4903.0</td>\n",
       "      <td>612.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3806</td>\n",
       "      <td>Mila</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3673.0</td>\n",
       "      <td>3667.0</td>\n",
       "      <td>611.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3675</td>\n",
       "      <td>Mateo</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3557.0</td>\n",
       "      <td>3551.0</td>\n",
       "      <td>591.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4763</td>\n",
       "      <td>Serenity</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4423.0</td>\n",
       "      <td>4415.0</td>\n",
       "      <td>551.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3488</td>\n",
       "      <td>Makayla</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3255.0</td>\n",
       "      <td>3248.0</td>\n",
       "      <td>464.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>538</td>\n",
       "      <td>Bella</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4155.0</td>\n",
       "      <td>4146.0</td>\n",
       "      <td>460.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>67</td>\n",
       "      <td>Aidan</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2652.0</td>\n",
       "      <td>2646.0</td>\n",
       "      <td>441.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>500</td>\n",
       "      <td>Bailey</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3058.0</td>\n",
       "      <td>3051.0</td>\n",
       "      <td>435.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>709</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6870.0</td>\n",
       "      <td>6853.0</td>\n",
       "      <td>403.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2010</td>\n",
       "      <td>Grayson</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5644.0</td>\n",
       "      <td>5630.0</td>\n",
       "      <td>402.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4728</td>\n",
       "      <td>Savannah</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5223.0</td>\n",
       "      <td>5210.0</td>\n",
       "      <td>400.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4639</td>\n",
       "      <td>Rylan</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2176.0</td>\n",
       "      <td>2170.0</td>\n",
       "      <td>361.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>156</td>\n",
       "      <td>Aliyah</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2084.0</td>\n",
       "      <td>2078.0</td>\n",
       "      <td>346.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4393</td>\n",
       "      <td>Reese</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2431.0</td>\n",
       "      <td>2424.0</td>\n",
       "      <td>346.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4600</td>\n",
       "      <td>Rowan</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1861.0</td>\n",
       "      <td>1855.0</td>\n",
       "      <td>309.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1634</td>\n",
       "      <td>Ellie</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3754.0</td>\n",
       "      <td>3741.0</td>\n",
       "      <td>287.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4080</td>\n",
       "      <td>Norah</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1715.0</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>284.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>644</td>\n",
       "      <td>Braxton</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3084.0</td>\n",
       "      <td>3073.0</td>\n",
       "      <td>279.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4189</td>\n",
       "      <td>Payton</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3076.0</td>\n",
       "      <td>3065.0</td>\n",
       "      <td>278.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1167</td>\n",
       "      <td>Dakota</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1923.0</td>\n",
       "      <td>1916.0</td>\n",
       "      <td>273.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2021</td>\n",
       "      <td>Griffin</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1610.0</td>\n",
       "      <td>1604.0</td>\n",
       "      <td>267.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2818</td>\n",
       "      <td>Keira</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>1556.0</td>\n",
       "      <td>259.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1914</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4294.0</td>\n",
       "      <td>4277.0</td>\n",
       "      <td>251.588235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3282</td>\n",
       "      <td>Liam</td>\n",
       "      <td>72.0</td>\n",
       "      <td>18088.0</td>\n",
       "      <td>18016.0</td>\n",
       "      <td>250.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2196</td>\n",
       "      <td>Isabelle</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2741.0</td>\n",
       "      <td>2730.0</td>\n",
       "      <td>248.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3428</td>\n",
       "      <td>Luna</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1722.0</td>\n",
       "      <td>1715.0</td>\n",
       "      <td>245.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687</th>\n",
       "      <td>1626</td>\n",
       "      <td>Eliud</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1688</th>\n",
       "      <td>4608</td>\n",
       "      <td>Roxie</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1689</th>\n",
       "      <td>5341</td>\n",
       "      <td>Thaddeus</td>\n",
       "      <td>208.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690</th>\n",
       "      <td>3980</td>\n",
       "      <td>Neftali</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1691</th>\n",
       "      <td>5747</td>\n",
       "      <td>Yusef</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1692</th>\n",
       "      <td>4783</td>\n",
       "      <td>Shaina</td>\n",
       "      <td>57.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.070175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1693</th>\n",
       "      <td>57</td>\n",
       "      <td>Agustin</td>\n",
       "      <td>138.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.065217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1694</th>\n",
       "      <td>312</td>\n",
       "      <td>Anna</td>\n",
       "      <td>5036.0</td>\n",
       "      <td>5353.0</td>\n",
       "      <td>317.0</td>\n",
       "      <td>0.062947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>3325</td>\n",
       "      <td>Lisandro</td>\n",
       "      <td>16.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696</th>\n",
       "      <td>2213</td>\n",
       "      <td>Isreal</td>\n",
       "      <td>16.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>190</td>\n",
       "      <td>Alyson</td>\n",
       "      <td>439.0</td>\n",
       "      <td>466.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.061503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>4700</td>\n",
       "      <td>Sandro</td>\n",
       "      <td>17.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>301</td>\n",
       "      <td>Anisha</td>\n",
       "      <td>34.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>2180</td>\n",
       "      <td>Ingrid</td>\n",
       "      <td>236.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.055085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1701</th>\n",
       "      <td>4207</td>\n",
       "      <td>Petra</td>\n",
       "      <td>74.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.054054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1702</th>\n",
       "      <td>225</td>\n",
       "      <td>Amin</td>\n",
       "      <td>37.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.054054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1703</th>\n",
       "      <td>4769</td>\n",
       "      <td>Servando</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.052632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704</th>\n",
       "      <td>5723</td>\n",
       "      <td>Yessenia</td>\n",
       "      <td>38.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.052632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705</th>\n",
       "      <td>2901</td>\n",
       "      <td>Keya</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.052632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1706</th>\n",
       "      <td>1946</td>\n",
       "      <td>Geronimo</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1707</th>\n",
       "      <td>5035</td>\n",
       "      <td>Sirena</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1708</th>\n",
       "      <td>1182</td>\n",
       "      <td>Damion</td>\n",
       "      <td>186.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.043011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1709</th>\n",
       "      <td>1361</td>\n",
       "      <td>Denis</td>\n",
       "      <td>74.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.040541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1710</th>\n",
       "      <td>737</td>\n",
       "      <td>Caitlin</td>\n",
       "      <td>596.0</td>\n",
       "      <td>618.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.036913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1711</th>\n",
       "      <td>4395</td>\n",
       "      <td>Regan</td>\n",
       "      <td>229.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.034934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1712</th>\n",
       "      <td>3627</td>\n",
       "      <td>Marlo</td>\n",
       "      <td>62.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.032258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1713</th>\n",
       "      <td>4645</td>\n",
       "      <td>Sabina</td>\n",
       "      <td>41.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.024390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1714</th>\n",
       "      <td>4286</td>\n",
       "      <td>Rafael</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>1174.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.015571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1715</th>\n",
       "      <td>1982</td>\n",
       "      <td>Giuseppe</td>\n",
       "      <td>74.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.013514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1716</th>\n",
       "      <td>1579</td>\n",
       "      <td>Efren</td>\n",
       "      <td>89.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.011236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1717 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index      name  y1_freq  y2_freq     diff         perc\n",
       "0      1061    Colton      6.0   6461.0   6455.0  1075.833333\n",
       "1       382      Aria      6.0   5117.0   5111.0   851.833333\n",
       "2      2195  Isabella     24.0  17574.0  17550.0   731.250000\n",
       "3      5040    Skylar      6.0   4225.0   4219.0   703.166667\n",
       "4      1077    Cooper      8.0   4911.0   4903.0   612.875000\n",
       "5      3806      Mila      6.0   3673.0   3667.0   611.166667\n",
       "6      3675     Mateo      6.0   3557.0   3551.0   591.833333\n",
       "7      4763  Serenity      8.0   4423.0   4415.0   551.875000\n",
       "8      3488   Makayla      7.0   3255.0   3248.0   464.000000\n",
       "9       538     Bella      9.0   4155.0   4146.0   460.666667\n",
       "10       67     Aidan      6.0   2652.0   2646.0   441.000000\n",
       "11      500    Bailey      7.0   3058.0   3051.0   435.857143\n",
       "12      709  Brooklyn     17.0   6870.0   6853.0   403.117647\n",
       "13     2010   Grayson     14.0   5644.0   5630.0   402.142857\n",
       "14     4728  Savannah     13.0   5223.0   5210.0   400.769231\n",
       "15     4639     Rylan      6.0   2176.0   2170.0   361.666667\n",
       "16      156    Aliyah      6.0   2084.0   2078.0   346.333333\n",
       "17     4393     Reese      7.0   2431.0   2424.0   346.285714\n",
       "18     4600     Rowan      6.0   1861.0   1855.0   309.166667\n",
       "19     1634     Ellie     13.0   3754.0   3741.0   287.769231\n",
       "20     4080     Norah      6.0   1715.0   1709.0   284.833333\n",
       "21      644   Braxton     11.0   3084.0   3073.0   279.363636\n",
       "22     4189    Payton     11.0   3076.0   3065.0   278.636364\n",
       "23     1167    Dakota      7.0   1923.0   1916.0   273.714286\n",
       "24     2021   Griffin      6.0   1610.0   1604.0   267.333333\n",
       "25     2818     Keira      6.0   1562.0   1556.0   259.333333\n",
       "26     1914   Genesis     17.0   4294.0   4277.0   251.588235\n",
       "27     3282      Liam     72.0  18088.0  18016.0   250.222222\n",
       "28     2196  Isabelle     11.0   2741.0   2730.0   248.181818\n",
       "29     3428      Luna      7.0   1722.0   1715.0   245.000000\n",
       "...     ...       ...      ...      ...      ...          ...\n",
       "1687   1626     Eliud     13.0     14.0      1.0     0.076923\n",
       "1688   4608     Roxie     13.0     14.0      1.0     0.076923\n",
       "1689   5341  Thaddeus    208.0    224.0     16.0     0.076923\n",
       "1690   3980   Neftali     14.0     15.0      1.0     0.071429\n",
       "1691   5747     Yusef     14.0     15.0      1.0     0.071429\n",
       "1692   4783    Shaina     57.0     61.0      4.0     0.070175\n",
       "1693     57   Agustin    138.0    147.0      9.0     0.065217\n",
       "1694    312      Anna   5036.0   5353.0    317.0     0.062947\n",
       "1695   3325  Lisandro     16.0     17.0      1.0     0.062500\n",
       "1696   2213    Isreal     16.0     17.0      1.0     0.062500\n",
       "1697    190    Alyson    439.0    466.0     27.0     0.061503\n",
       "1698   4700    Sandro     17.0     18.0      1.0     0.058824\n",
       "1699    301    Anisha     34.0     36.0      2.0     0.058824\n",
       "1700   2180    Ingrid    236.0    249.0     13.0     0.055085\n",
       "1701   4207     Petra     74.0     78.0      4.0     0.054054\n",
       "1702    225      Amin     37.0     39.0      2.0     0.054054\n",
       "1703   4769  Servando     19.0     20.0      1.0     0.052632\n",
       "1704   5723  Yessenia     38.0     40.0      2.0     0.052632\n",
       "1705   2901      Keya     19.0     20.0      1.0     0.052632\n",
       "1706   1946  Geronimo     21.0     22.0      1.0     0.047619\n",
       "1707   5035    Sirena     21.0     22.0      1.0     0.047619\n",
       "1708   1182    Damion    186.0    194.0      8.0     0.043011\n",
       "1709   1361     Denis     74.0     77.0      3.0     0.040541\n",
       "1710    737   Caitlin    596.0    618.0     22.0     0.036913\n",
       "1711   4395     Regan    229.0    237.0      8.0     0.034934\n",
       "1712   3627     Marlo     62.0     64.0      2.0     0.032258\n",
       "1713   4645    Sabina     41.0     42.0      1.0     0.024390\n",
       "1714   4286    Rafael   1156.0   1174.0     18.0     0.015571\n",
       "1715   1982  Giuseppe     74.0     75.0      1.0     0.013514\n",
       "1716   1579     Efren     89.0     90.0      1.0     0.011236\n",
       "\n",
       "[1717 rows x 6 columns]"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
